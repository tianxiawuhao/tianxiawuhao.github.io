<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta content="yes" name="apple-mobile-web-app-capable" />
<meta content="black" name="apple-mobile-web-app-status-bar-style" />
<meta name="referrer" content="never">
<meta name="keywords" content="">
<meta name="description" content="欢迎访问[tianxia]的个人博客">
<meta name="author" content="kveln">
<title>LoRA_PEFT | tianxia</title>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.0/dist/css/bootstrap.min.css">
<link href="https://cdn.bootcss.com/font-awesome/5.11.2/css/all.min.css" rel="stylesheet">
<link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
<link
  href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800'
  rel='stylesheet' type='text/css'>
<link rel="alternate" type="application/rss+xml" title="LoRA_PEFT | tianxia » Feed"
  href="https://tianxiawuhao.github.io/atom.xml">
<link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.15.10/build/styles/androidstudio.min.css">
<link href="https://tianxiawuhao.github.io/styles/main.css" rel="stylesheet">
<script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/@highlightjs/cdn-assets/highlight.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/850552586/ericamcdn@0.1/css/live2d.css">

<script>hljs.initHighlightingOnLoad();</script>

  <meta property="og:description" content="LoRA_PEFT" />
  <meta property="og:url" content="https://tianxiawuhao.github.io/GL2xUsgbSZ/" />
  <meta property="og:locale" content="zh-CN" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="tianxia" />
  <!-- <script src="../assets/styles/scripts/tocScript.js"></script> -->
</head>

<body>
  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
  <div class="container">
    <a class="navbar-brand" href="https://tianxiawuhao.github.io">tianxia</a>
    <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
      data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
      aria-label="Toggle navigation">
      Menu
      <i class="fas fa-bars"></i>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item">
          
          <a class="nav-link" href="https://tianxiawuhao.github.io">首页</a>
          
        </li>
        
        <li class="nav-item">
          
          <a class="nav-link" href="/archives">归档</a>
          
        </li>
        
        <li class="nav-item">
          
          <a class="nav-link" href="/tags">标签</a>
          
        </li>
        
        <li class="nav-item">
          <div class="gridea-search-container">
            <form id="gridea-search-form" style="position: relative" data-update="1742729663519"
              action="/search/index.html">
              <input class="search-input" autocomplete="off" spellcheck="false" name="q" placeholder="搜索文章" />
              <i class="fas fa-search gt-c-content-color-first" style="position: absolute; top: 9px; left: 10px;"></i>
            </form>
          </div>
        </li>
      </ul>
    </div>
  </div>
</nav>
  <!-- Page Header -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
  <div class="container">
    <a class="navbar-brand" href="https://tianxiawuhao.github.io">tianxia</a>
    <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
      data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
      aria-label="Toggle navigation">
      Menu
      <i class="fas fa-bars"></i>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item">
          
          <a class="nav-link" href="https://tianxiawuhao.github.io">首页</a>
          
        </li>
        
        <li class="nav-item">
          
          <a class="nav-link" href="/archives">归档</a>
          
        </li>
        
        <li class="nav-item">
          
          <a class="nav-link" href="/tags">标签</a>
          
        </li>
        
        <li class="nav-item">
          <div class="gridea-search-container">
            <form id="gridea-search-form" style="position: relative" data-update="1742729663519"
              action="/search/index.html">
              <input class="search-input" autocomplete="off" spellcheck="false" name="q" placeholder="搜索文章" />
              <i class="fas fa-search gt-c-content-color-first" style="position: absolute; top: 9px; left: 10px;"></i>
            </form>
          </div>
        </li>
      </ul>
    </div>
  </div>
</nav>
<header class="masthead" style="background-image: url('https://tianxiawuhao.github.io/media/images/home-bg.jpg')">
  <div class="overlay"></div>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-md-10 mx-auto">
        
          <!-- 没Title为其他页面Header -->
          
            <!-- 没Title并且有headerType为Post：文章Header -->
            <div class="post-heading">
              <span class="tags">
                
                <a href="https://tianxiawuhao.github.io/PjnFH7MKT/" class="tag">机器学习</a>
                
              </span>
              <h1>LoRA_PEFT</h1>
              <span class="meta">
                Posted on
                2025-02-18，4 min read
              </span>
            </div>
          
        
      </div>
    </div>
  </div>
</header>
  <!-- Post Content -->
  <article id="post-content-article">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto post-content-container">
          
          <img class="post-feature-header-image" src="https://tianxiawuhao.github.io/post-images/GL2xUsgbSZ.png" alt="封面图">
          </img>
          
          <ol>
<li><strong>模型加载</strong>：使用4位量化(<code>load_in_4bit=True</code>)减少显存消耗，可根据硬件调整</li>
<li><strong>LoRA配置</strong>：
<ul>
<li><code>target_modules</code>需要根据模型结构调整，通常选择注意力层的query/value投影矩阵</li>
<li>秩<code>r</code>控制LoRA的维度，通常8-64之间</li>
<li><code>lora_alpha</code>控制缩放系数，一般设置为r的2-4倍</li>
</ul>
</li>
<li><strong>数据处理</strong>：
<ul>
<li>确保数据集包含&quot;text&quot;字段，或根据实际数据调整预处理函数</li>
<li>使用<code>DataCollatorForLanguageModeling</code>进行动态填充</li>
</ul>
</li>
<li><strong>训练优化</strong>：
<ul>
<li>通过<code>gradient_accumulation_steps</code>模拟更大的batch size</li>
<li>混合精度(<code>fp16=True</code>)减少显存占用</li>
<li>使用<code>bitsandbytes</code>库进行量化训练</li>
</ul>
</li>
</ol>
<pre><code class="language-python"># 环境依赖（需提前安装）
# pip install torch transformers datasets peft accelerate bitsandbytes

import torch
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from datasets import load_dataset

# ===================== 配置参数 =====================
MODEL_NAME = &quot;deepseek-ai/deepseek-r1&quot;  # 确认HuggingFace模型ID
DATASET_NAME = &quot;your_dataset&quot;          # 数据集名称或本地路径
OUTPUT_DIR = &quot;./deepseek-r1-lora-finetuned&quot;
BATCH_SIZE = 2                         # 根据GPU显存调整
MAX_LENGTH = 1024                      # 模型支持的最大上下文长度
NUM_EPOCHS = 3
LEARNING_RATE = 3e-5

# LoRA配置
LORA_R = 16
LORA_ALPHA = 64
LORA_DROPOUT = 0.05
TARGET_MODULES = [&quot;q_proj&quot;, &quot;v_proj&quot;]  # 关键参数！需根据实际模型结构调整

# ===================== 模型加载 =====================
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    load_in_4bit=True,                  # 4bit量化节省显存
    device_map=&quot;auto&quot;,
    torch_dtype=torch.bfloat16,
    attn_implementation=&quot;flash_attention_2&quot;  # 如果支持Flash Attention
)

# 处理特殊token
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# 准备量化训练
model = prepare_model_for_kbit_training(model)

# ===================== LoRA配置 =====================
peft_config = LoraConfig(
    r=LORA_R,
    lora_alpha=LORA_ALPHA,
    lora_dropout=LORA_DROPOUT,
    target_modules=TARGET_MODULES,  # 关键配置项！
    bias=&quot;none&quot;,
    task_type=&quot;CAUSAL_LM&quot;,
    modules_to_save=[&quot;lm_head&quot;]     # 同时微调输出层
)

model = get_peft_model(model, peft_config)
model.print_trainable_parameters()  # 输出示例：trainable params: 21,233,664 || all params: 6,742,097,920 || trainable%: 0.3148

# ===================== 数据处理 =====================
def format_function(examples):
    # 根据任务构造prompt，示例：
    texts = [
        f&quot;&lt;|System|&gt;\n你是一个AI助手\n&lt;|User|&gt;\n{query}\n&lt;|Assistant|&gt;\n{answer}&quot;
        for query, answer in zip(examples[&quot;query&quot;], examples[&quot;answer&quot;])
    ]
    return {&quot;text&quot;: texts}

dataset = load_dataset(DATASET_NAME)
dataset = dataset.map(format_function, batched=True)

def tokenize_function(examples):
    return tokenizer(
        examples[&quot;text&quot;],
        max_length=MAX_LENGTH,
        padding=&quot;max_length&quot;,
        truncation=True,
        add_special_tokens=True
    )

tokenized_dataset = dataset.map(tokenize_function, batched=True)

# ===================== 训练配置 =====================
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    num_train_epochs=NUM_EPOCHS,
    per_device_train_batch_size=BATCH_SIZE,
    gradient_accumulation_steps=8,       # 模拟更大batch size
    learning_rate=LEARNING_RATE,
    fp16=True,                            # 混合精度训练
    optim=&quot;paged_adamw_8bit&quot;,            # 优化器选择
    logging_steps=20,
    save_strategy=&quot;steps&quot;,
    save_steps=500,
    evaluation_strategy=&quot;steps&quot;,          # 如果有验证集
    eval_steps=300,
    report_to=&quot;tensorboard&quot;,
    gradient_checkpointing=True,          # 显存优化
    ddp_find_unused_parameters=False
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset[&quot;train&quot;],
    eval_dataset=tokenized_dataset[&quot;test&quot;],  # 如果有验证集
    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),
)

# ===================== 开始训练 =====================
trainer.train()
model.save_pretrained(OUTPUT_DIR)
tokenizer.save_pretrained(OUTPUT_DIR)

# ===================== 推理测试 =====================
from peft import PeftModel

base_model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    device_map=&quot;auto&quot;,
    torch_dtype=torch.bfloat16
)
model = PeftModel.from_pretrained(base_model, OUTPUT_DIR)

inputs = tokenizer(
    &quot;&lt;|System|&gt;\n你是一个AI助手\n&lt;|User|&gt;\n如何学习机器学习？\n&lt;|Assistant|&gt;\n&quot;,
    return_tensors=&quot;pt&quot;
).to(&quot;cuda&quot;)

outputs = model.generate(
    **inputs,
    max_new_tokens=256,
    temperature=0.7,
    do_sample=True
)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
</code></pre>

          <div class="toc-container"></div>
          <hr />
          
            <p class="prev-post">上一篇：
              <a href="https://tianxiawuhao.github.io/n7vyn_1QRC/">
                <span class="post-title">
                  LoRA（Low-Rank Adaptation）&rarr;
                </span>
              </a>
            </p>
          
          
          <p class="next-post">下一篇：
            <a href="https://tianxiawuhao.github.io/1I3syISgB_/">
              <span class="post-title">
                大模型框架体系&rarr;
              </span>
            </a>
          </p>
          
          <div class="comment" style="text-align: center;">
            

            
            
          </div>
        </div>
      </div>
    </div>
  </article>
  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <ul class="list-inline text-center">
            
            
              
            
              
            
              
            
              
            
              
            
              
            
              
              <!-- <li class="list-inline-item">
              <a href="https://tianxiawuhao.github.io/atom.xml" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
                </span>
              </a>
              </li> -->
          </ul>
          <p class="copyright text-muted">Copyright &copy;<span>tianxia</span><br><a href="https://github.com/getgridea/gridea" class="Themeinfo">Powered by Gridea</a></p>
        </div>
      </div>
    </div>
   </footer>
  <!-- Bootstrap core JavaScript -->
  <script src="https://cdn.bootcss.com/twitter-bootstrap/4.3.1/js/bootstrap.bundle.min.js"></script>
  <!-- <script src="https://tianxiawuhao.github.io/media/scripts/bootstrap.bundle.min.js"></script> -->
  <!-- Bootstrap core JavaScript -->
  <script src="https://cdn.jsdelivr.net/gh/Alanrk/clean-cdn@1.0/scripts/clean-blog.min.js"></script>
  <!-- <script src="https://tianxiawuhao.github.io/media/scripts/clean-blog.min.js"></script> -->
  <script src="//instant.page/3.0.0" type="module" defer integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1"></script>
  <style type="text/css">a.back_to_top{text-decoration:none;position:fixed;bottom:40px;right:30px;background:#f0f0f0;height:40px;width:40px;border-radius:50%;line-height:36px;font-size:18px;text-align:center;transition-duration:.5s;transition-propety:background-color;display:none}a.back_to_top span{color:#888}a.back_to_top:hover{cursor:pointer;background:#dfdfdf}a.back_to_top:hover span{color:#555}@media print,screen and(max-width:580px){.back_to_top{display:none!important}}</style>
<a id="back_to_top" href="#" class="back_to_top">
  <span>▲</span></a>
<script>$(document).ready((function(_this) {
    return function() {
      var bt;
      bt = $('#back_to_top');
      if ($(document).width() > 480) {
        $(window).scroll(function() {
          var st;
          st = $(window).scrollTop();
          if (st > 30) {
            return bt.css('display', 'block')
          } else {
            return bt.css('display', 'none')
          }
        });
        return bt.click(function() {
          $('body,html').animate({
            scrollTop: 0
          },
          800);
          return false
        })
      }
    }
  })(this));</script>
  
  <script src="https://tianxiawuhao.github.io/media/scripts/tocScript.js"></script>
</body>

</html>