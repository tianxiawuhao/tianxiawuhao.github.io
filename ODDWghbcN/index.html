<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta content="yes" name="apple-mobile-web-app-capable" />
<meta content="black" name="apple-mobile-web-app-status-bar-style" />
<meta name="referrer" content="never">
<meta name="keywords" content="">
<meta name="description" content="欢迎访问[tianxia]的个人博客">
<meta name="author" content="kveln">
<title>第十章 Table API 与 SQL | tianxia</title>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.0/dist/css/bootstrap.min.css">
<link href="https://cdn.bootcss.com/font-awesome/5.11.2/css/all.min.css" rel="stylesheet">
<link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
<link
  href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800'
  rel='stylesheet' type='text/css'>
<link rel="alternate" type="application/rss+xml" title="第十章 Table API 与 SQL | tianxia » Feed"
  href="https://tianxiawuhao.github.io/atom.xml">
<link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.15.10/build/styles/androidstudio.min.css">
<link href="https://tianxiawuhao.github.io/styles/main.css" rel="stylesheet">
<script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/@highlightjs/cdn-assets/highlight.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/850552586/ericamcdn@0.1/css/live2d.css">

<script>hljs.initHighlightingOnLoad();</script>

  <meta property="og:description" content="第十章 Table API 与 SQL" />
  <meta property="og:url" content="https://tianxiawuhao.github.io/ODDWghbcN/" />
  <meta property="og:locale" content="zh-CN" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="tianxia" />
  <!-- <script src="../assets/styles/scripts/tocScript.js"></script> -->
</head>

<body>
  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
  <div class="container">
    <a class="navbar-brand" href="https://tianxiawuhao.github.io">tianxia</a>
    <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
      data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
      aria-label="Toggle navigation">
      Menu
      <i class="fas fa-bars"></i>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item">
          
          <a class="nav-link" href="https://tianxiawuhao.github.io">首页</a>
          
        </li>
        
        <li class="nav-item">
          
          <a class="nav-link" href="/archives">归档</a>
          
        </li>
        
        <li class="nav-item">
          
          <a class="nav-link" href="/tags">标签</a>
          
        </li>
        
        <li class="nav-item">
          <div class="gridea-search-container">
            <form id="gridea-search-form" style="position: relative" data-update="1742729663519"
              action="/search/index.html">
              <input class="search-input" autocomplete="off" spellcheck="false" name="q" placeholder="搜索文章" />
              <i class="fas fa-search gt-c-content-color-first" style="position: absolute; top: 9px; left: 10px;"></i>
            </form>
          </div>
        </li>
      </ul>
    </div>
  </div>
</nav>
  <!-- Page Header -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
  <div class="container">
    <a class="navbar-brand" href="https://tianxiawuhao.github.io">tianxia</a>
    <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
      data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
      aria-label="Toggle navigation">
      Menu
      <i class="fas fa-bars"></i>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item">
          
          <a class="nav-link" href="https://tianxiawuhao.github.io">首页</a>
          
        </li>
        
        <li class="nav-item">
          
          <a class="nav-link" href="/archives">归档</a>
          
        </li>
        
        <li class="nav-item">
          
          <a class="nav-link" href="/tags">标签</a>
          
        </li>
        
        <li class="nav-item">
          <div class="gridea-search-container">
            <form id="gridea-search-form" style="position: relative" data-update="1742729663519"
              action="/search/index.html">
              <input class="search-input" autocomplete="off" spellcheck="false" name="q" placeholder="搜索文章" />
              <i class="fas fa-search gt-c-content-color-first" style="position: absolute; top: 9px; left: 10px;"></i>
            </form>
          </div>
        </li>
      </ul>
    </div>
  </div>
</nav>
<header class="masthead" style="background-image: url('https://tianxiawuhao.github.io/media/images/home-bg.jpg')">
  <div class="overlay"></div>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-md-10 mx-auto">
        
          <!-- 没Title为其他页面Header -->
          
            <!-- 没Title并且有headerType为Post：文章Header -->
            <div class="post-heading">
              <span class="tags">
                
              </span>
              <h1>第十章 Table API 与 SQL</h1>
              <span class="meta">
                Posted on
                2021-04-18，28 min read
              </span>
            </div>
          
        
      </div>
    </div>
  </div>
</header>
  <!-- Post Content -->
  <article id="post-content-article">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto post-content-container">
          
          <img class="post-feature-header-image" src="https://tianxiawuhao.github.io/post-images/ODDWghbcN.png" alt="封面图">
          </img>
          
          <h1 id="flink-tablesql">Flink Table&amp;SQL</h1>
<blockquote>
<p>flink table &amp; sql时间属性与窗口<br>
flink版本：1.13.1<br>
scala版本：2.12</p>
</blockquote>
<h2 id="maven-依赖引用">maven 依赖引用</h2>
<pre><code class="language-xml"> &lt;!-- 使用table api 引入的依赖，使用桥接器和底层datastream api连接支持--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-table-api-java-bridge_${scala.binary.version}&lt;/artifactId&gt;
    &lt;version&gt;${flink.version}&lt;/version&gt;
&lt;/dependency&gt;

&lt;!--如果需要在本地运行table api和sql 还需要引入一下依赖--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-table-planner-blink_${scala.binary.version}&lt;/artifactId&gt;
    &lt;version&gt;${flink.version}&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-streaming-scala_${scala.binary.version}&lt;/artifactId&gt;
    &lt;version&gt;${flink.version}&lt;/version&gt;
&lt;/dependency&gt;

&lt;!--如果想实现自定义的数据格式来做序列化，需要引入一下依赖--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-table-common&lt;/artifactId&gt;
    &lt;version&gt;${flink.version}&lt;/version&gt;
&lt;/dependency&gt;

&lt;!--连接外部数据格式解析,采用csv方式来解析--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-csv&lt;/artifactId&gt;
    &lt;version&gt;${flink.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h1 id="时间属性">时间属性</h1>
<h2 id="1-事件时间">1 事件时间</h2>
<p>在DDL连接表中创建</p>
<pre><code class="language-java">CREATE TABLE EventTable(
 user STRING,
 url STRING,
 ts TIMESTAMP(3), // 传入得值是bigint,自动转换
 WATERMARK FOR ts AS ts - INTERVAL '5' SECOND
) WITH (
 ...
);
</code></pre>
<p>说明：</p>
<p>这里我们把 ts 字段定义为事件时间属性，而且基于 ts 设置了 5 秒的水位线延迟。<br>
这里的“5 秒”是以“时间间隔”的形式定义的，格式是 INTERVAL &lt;数值&gt; &lt;时间单位&gt;：INTERVAL ‘5’ SECOND，这里的数值必须用单引号引起来，而单位用 SECOND 和 SECONDS 是等效的。<br>
TIMESTAMP会自动转为国际UTF时间，使用当地时间需要使用TIMESTAMP_LTZ</p>
<pre><code class="language-java">CREATE TABLE events (
 user STRING,
 url STRING,
 ts BIGINT,
 ts_ltz AS TO_TIMESTAMP_LTZ(ts, 3),
 WATERMARK FOR ts_ltz AS ts_ltz - INTERVAL '5' SECOND
) WITH (
 ...
);
</code></pre>
<p>说明：</p>
<blockquote>
<p>Flink 中支持的事件时间属性数据类型必须为 TIMESTAMP 或者 TIMESTAMP_LTZ。这里<br>
TIMESTAMP_LTZ 是指带有本地时区信息的时间戳（TIMESTAMP WITH LOCAL TIME<br>
ZONE）；一般情况下如果数据中的时间戳是“年-月-日-时-分-秒”的形式，那就是不带时区信<br>
息的，可以将事件时间属性定义为 TIMESTAMP 类型。</p>
</blockquote>
<p>而如果原始的时间戳就是一个长整型的毫秒数，这时就需要另外定义一个字段来表示事件<br>
时间属性，类型定义为 TIMESTAMP_LTZ 会更方便。</p>
<p>在数据流转换为表时定义</p>
<pre><code class="language-java">public class TimeAndWindowTest {
    public static void main(String[] args) throws Exception{
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);

        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);

        //2.在流转换成Table的时候定义时间属性
        SingleOutputStreamOperator&lt;Event&gt; clickStream = env.addSource(new ClickSource())
                .assignTimestampsAndWatermarks(WatermarkStrategy.&lt;Event&gt;forBoundedOutOfOrderness(Duration.ZERO)
                        .withTimestampAssigner(new SerializableTimestampAssigner&lt;Event&gt;() {
                            @Override
                            public long extractTimestamp(Event element, long recordTimestamp) {
                                return element.timestamp;
                            }
                        }));
        Table clickTable = tableEnv.fromDataStream(clickStream, $(&quot;user&quot;), $(&quot;url&quot;), $(&quot;timestamp&quot;).as(&quot;ts&quot;),
                $(&quot;et&quot;).rowtime());

        clickTable.printSchema();
    }
}
</code></pre>
<p>说明</p>
<blockquote>
<p>设置水位线(assignTimestampsAndWatermarks),<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi mathvariant="normal">“</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">”</mi><mo>)</mo><mi mathvariant="normal">.</mi><mi>r</mi><mi>o</mi><mi>w</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mo>(</mo><mo>)</mo><mi mathvariant="normal">自</mi><mi mathvariant="normal">动</mi><mi mathvariant="normal">获</mi><mi mathvariant="normal">取</mi><mi mathvariant="normal">，</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">为</mi><mi mathvariant="normal">虚</mi><mi mathvariant="normal">拟</mi><mi mathvariant="normal">表</mi><mi mathvariant="normal">别</mi><mi mathvariant="normal">名</mi></mrow><annotation encoding="application/x-tex">(“et”).rowtime()自动获取，et为虚拟表别名
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">“</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord">”</span><span class="mclose">)</span><span class="mord">.</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mopen">(</span><span class="mclose">)</span><span class="mord cjk_fallback">自</span><span class="mord cjk_fallback">动</span><span class="mord cjk_fallback">获</span><span class="mord cjk_fallback">取</span><span class="mord cjk_fallback">，</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord cjk_fallback">为</span><span class="mord cjk_fallback">虚</span><span class="mord cjk_fallback">拟</span><span class="mord cjk_fallback">表</span><span class="mord cjk_fallback">别</span><span class="mord cjk_fallback">名</span></span></span></span>(“ps”).proctime()表示系统处理时间，ps为虚拟表别名<br>
.rowtime()，.proctime()值均是国际UTF时间</p>
</blockquote>
<h2 id="2-处理时间">2 处理时间</h2>
<pre><code class="language-java">在创建表的 DDL 中定义
CREATE TABLE EventTable(
 user STRING,
 url STRING,
 ts AS PROCTIME()
) WITH (
 ...
);
</code></pre>
<p>在数据流转换为表时定义</p>
<pre><code class="language-java">DataStream&lt;Tuple2&lt;String, String&gt;&gt; stream = ...;
// 声明一个额外的字段作为处理时间属性字段，$(&quot;ts&quot;).proctime()系统处理时间
Table table = tEnv.fromDataStream(stream, $(&quot;user&quot;), $(&quot;url&quot;), $(&quot;ts&quot;).proctime());
</code></pre>
<h2 id="11-案例1datastream-sql统计">1.1 案例1（DataStream SQL统计）</h2>
<p><strong>需求：将DataStream注册为Table和View并进行SQL统计。</strong></p>
<p>代码如下：</p>
<pre><code class="language-java">import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.Table;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

import java.util.Arrays;

import static org.apache.flink.table.api.Expressions.$;

/**
 * 案例1：将DataStream注册为Table和View并进行SQL统计
 */
public class Demo1 {

    public static void main(String[] args) throws Exception {
        //1.准备环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        //EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();
        //StreamTableEnvironment tEnv = StreamTableEnvironment.create(env, settings);
        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);

        //2.Source
        DataStream&lt;Order&gt; orderA = env.fromCollection(Arrays.asList(
                new Order(1L, &quot;beer&quot;, 3),
                new Order(1L, &quot;diaper&quot;, 4),
                new Order(3L, &quot;rubber&quot;, 2)));

        DataStream&lt;Order&gt; orderB = env.fromCollection(Arrays.asList(
                new Order(2L, &quot;pen&quot;, 3),
                new Order(2L, &quot;rubber&quot;, 3),
                new Order(4L, &quot;beer&quot;, 1)));

        //3.注册表
        // convert DataStream to Table
        Table tableA = tEnv.fromDataStream(orderA, $(&quot;user&quot;), $(&quot;product&quot;), $(&quot;amount&quot;));
        // register DataStream as Table
        tEnv.createTemporaryView(&quot;OrderB&quot;, orderB, $(&quot;user&quot;), $(&quot;product&quot;), $(&quot;amount&quot;));

        //4.执行查询
        System.out.println(tableA);
        // union the two tables
        Table resultTable = tEnv.sqlQuery(
                &quot;SELECT * FROM &quot; + tableA + &quot; WHERE amount &gt; 2 &quot; +
                        &quot;UNION ALL &quot; +
                        &quot;SELECT * FROM OrderB WHERE amount &lt; 2&quot;
        );

        //5.输出结果
        DataStream&lt;Order&gt; resultDS = tEnv.toAppendStream(resultTable, Order.class);
        resultDS.print();

        env.execute();

    }

    @Data
    @NoArgsConstructor
    @AllArgsConstructor
    public static class Order {
        public Long user;
        public String product;
        public int amount;
    }

}
</code></pre>
<p>运行结果：<br>
<img src="https://tianxiawuhao.github.io/post-images/1681542069704.png" alt="" loading="lazy"></p>
<h2 id="12-案例2datastream-tablesql统计">1.2 案例2（DataStream Table&amp;SQL统计）</h2>
<p><strong>需求：使用SQL和Table两种方式对DataStream中的单词进行统计。</strong></p>
<p>示例代码如下（SQL方式）：</p>
<pre><code class="language-java">import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.Table;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

import static org.apache.flink.table.api.Expressions.$;

/**
 * 使用SQL和Table两种方式对DataStream中的单词进行统计。
 *
 */
public class Demo02 {

    public static void main(String[] args) throws Exception {
        //1.准备环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);

        //2.Source
        DataStream&lt;WC&gt; input = env.fromElements(
                new WC(&quot;Hello&quot;, 1),
                new WC(&quot;World&quot;, 1),
                new WC(&quot;Hello&quot;, 1)
        );

        //3.注册表
        tEnv.createTemporaryView(&quot;WordCount&quot;, input, $(&quot;word&quot;), $(&quot;frequency&quot;));

        //4.执行查询
        Table resultTable = tEnv.sqlQuery(&quot;SELECT word, SUM(frequency) as frequency FROM WordCount GROUP BY word&quot;);

        //5.输出结果
        //toAppendStream doesn't support consuming update changes which is produced by node GroupAggregate
        //DataStream&lt;WC&gt; resultDS = tEnv.toAppendStream(resultTable, WC.class);
        DataStream&lt;Tuple2&lt;Boolean, WC&gt;&gt; resultDS = tEnv.toRetractStream(resultTable, WC.class);

        resultDS.print();

        env.execute();

    }

    @Data
    @NoArgsConstructor
    @AllArgsConstructor
    public static class WC {
        public String word;
        public long frequency;
    }
}
</code></pre>
<p>运行结果：</p>
<figure data-type="image" tabindex="1"><img src="https://tianxiawuhao.github.io/post-images/1681542097729.png" alt="" loading="lazy"></figure>
<p>示例代码如下（Table方式）：</p>
<pre><code class="language-java">import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.Table;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

import static org.apache.flink.table.api.Expressions.$;

/**
 * 使用SQL和Table两种方式对DataStream中的单词进行统计
 *
 */
public class Demo02Table {
    public static void main(String[] args) throws Exception {
        //1.准备环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);

        //2.Source
        DataStream&lt;WC&gt; input = env.fromElements(
                new WC(&quot;Hello&quot;, 1),
                new WC(&quot;World&quot;, 1),
                new WC(&quot;Hello&quot;, 1)
        );

        //3.注册表
        Table table = tEnv.fromDataStream(input);

        //4.执行查询
        Table resultTable = table
                .groupBy($(&quot;word&quot;))
                .select($(&quot;word&quot;), $(&quot;frequency&quot;).sum().as(&quot;frequency&quot;))
                .filter($(&quot;frequency&quot;).isEqual(2));

        //5.输出结果
        DataStream&lt;Tuple2&lt;Boolean, WC&gt;&gt; resultDS = tEnv.toRetractStream(resultTable, WC.class);

        resultDS.print();

        env.execute();

    }

    @Data
    @NoArgsConstructor
    @AllArgsConstructor
    public static class WC {
        public String word;
        public long frequency;
    }
}
</code></pre>
<h2 id="14-案例4sql消费kafka">1.4 案例4（SQL消费Kafka）</h2>
<p><strong>需求：从Kafka中消费数据并过滤出状态为success的数据再写入到Kafka</strong></p>
<pre><code class="language-java">{&quot;user_id&quot;: &quot;1&quot;, &quot;page_id&quot;:&quot;1&quot;, &quot;status&quot;: &quot;success&quot;}
{&quot;user_id&quot;: &quot;1&quot;, &quot;page_id&quot;:&quot;1&quot;, &quot;status&quot;: &quot;success&quot;}
{&quot;user_id&quot;: &quot;1&quot;, &quot;page_id&quot;:&quot;1&quot;, &quot;status&quot;: &quot;success&quot;}
{&quot;user_id&quot;: &quot;1&quot;, &quot;page_id&quot;:&quot;1&quot;, &quot;status&quot;: &quot;success&quot;}
{&quot;user_id&quot;: &quot;1&quot;, &quot;page_id&quot;:&quot;1&quot;, &quot;status&quot;: &quot;fail&quot;}
</code></pre>
<pre><code class="language-java">/export/server/kafka/bin/kafka-topics.sh --create --zookeeper node1:2181 --replication-factor 2 --partitions 3 --topic input_kafka

/export/server/kafka/bin/kafka-topics.sh --create --zookeeper node1:2181 --replication-factor 2 --partitions 3 --topic output_kafka

/export/server/kafka/bin/kafka-console-producer.sh --broker-list node1:9092 --topic input_kafka

/export/server/kafka/bin/kafka-console-consumer.sh --bootstrap-server node1:9092 --topic output_kafka --from-beginning
</code></pre>
<p>代码实现：</p>
<blockquote>
<p>https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/<br>
https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/connectors/kafka.html</p>
</blockquote>
<pre><code class="language-java">import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.Table;
import org.apache.flink.table.api.TableResult;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;
import org.apache.flink.types.Row;

/**
 * 从Kafka中消费数据并过滤出状态为success的数据再写入到Kafka
 */
public class Demo4 {

    public static void main(String[] args) throws Exception {
        //1.准备环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);

        //2.Source
        TableResult inputTable = tEnv.executeSql(
                &quot;CREATE TABLE input_kafka (\n&quot; +
                        &quot;  `user_id` BIGINT,\n&quot; +
                        &quot;  `page_id` BIGINT,\n&quot; +
                        &quot;  `status` STRING\n&quot; +
                        &quot;) WITH (\n&quot; +
                        &quot;  'connector' = 'kafka',\n&quot; +
                        &quot;  'topic' = 'input_kafka',\n&quot; +
                        &quot;  'properties.bootstrap.servers' = 'node1:9092',\n&quot; +
                        &quot;  'properties.group.id' = 'testGroup',\n&quot; +
                        &quot;  'scan.startup.mode' = 'latest-offset',\n&quot; +
                        &quot;  'format' = 'json'\n&quot; +
                        &quot;)&quot;
        );
        TableResult outputTable = tEnv.executeSql(
                &quot;CREATE TABLE output_kafka (\n&quot; +
                        &quot;  `user_id` BIGINT,\n&quot; +
                        &quot;  `page_id` BIGINT,\n&quot; +
                        &quot;  `status` STRING\n&quot; +
                        &quot;) WITH (\n&quot; +
                        &quot;  'connector' = 'kafka',\n&quot; +
                        &quot;  'topic' = 'output_kafka',\n&quot; +
                        &quot;  'properties.bootstrap.servers' = 'node1:9092',\n&quot; +
                        &quot;  'format' = 'json',\n&quot; +
                        &quot;  'sink.partitioner' = 'round-robin'\n&quot; +
                        &quot;)&quot;
        );

        String sql = &quot;select &quot; +
                &quot;user_id,&quot; +
                &quot;page_id,&quot; +
                &quot;status &quot; +
                &quot;from input_kafka &quot; +
                &quot;where status = 'success'&quot;;

        Table ResultTable = tEnv.sqlQuery(sql);

        DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; resultDS = tEnv.toRetractStream(ResultTable, Row.class);
        resultDS.print();

        tEnv.executeSql(&quot;insert into output_kafka select * from &quot; + ResultTable);


        //7.excute
        env.execute();
    }

}
</code></pre>
<h1 id="2-flink-sql常用算子">2 Flink SQL常用算子</h1>
<h2 id="21-select">2.1 SELECT</h2>
<blockquote>
<p>SELECT ：用于从 DataSet/DataStream 中选择数据，用于筛选出某些列。</p>
</blockquote>
<p><strong>示例：</strong></p>
<ul>
<li>
<p>SELECT * FROM Table；// 取出表中的所有列</p>
</li>
<li>
<p>SELECT name，age FROM Table；// 取出表中 name 和 age两列</p>
</li>
</ul>
<p>与此同时 SELECT语句中可以使用函数和别名，例如我们上面提到的 WordCount中：</p>
<pre><code class="language-sql">SELECT word, COUNT(word) FROM table GROUP BY word; 
</code></pre>
<h2 id="22-where">2.2 WHERE</h2>
<blockquote>
<p>WHERE ：用于从数据集/流中过滤数据，与 SELECT 一起使用，用于根据某些条件对关系做水平分割，即选择符合条件的记录。</p>
</blockquote>
<p>示例：</p>
<ul>
<li>
<p>SELECT name，age FROM Table where name LIKE ‘% 小明 %’；</p>
</li>
<li>
<p>SELECT * FROM Table WHERE age = 20；</p>
</li>
</ul>
<p>WHERE是从原数据中进行过滤，那么在WHERE条件中，Flink SQL同样支持 =、&lt;、&gt;、&lt;&gt;、&gt;=、&lt;=，以及 AND、OR等表达式的组合，最终满足过滤条件的数据会被选择出来。并且 WHERE 可以结合IN、NOT IN联合使用。举个例子：</p>
<pre><code class="language-sql">SELECT name, age
FROM Table
WHERE name IN (SELECT name FROM Table2)
</code></pre>
<h2 id="23-distinct">2.3 DISTINCT</h2>
<blockquote>
<p>DISTINCT： 用于从数据集/流中去重根据 SELECT 的结果进行去重。</p>
</blockquote>
<p>示例：</p>
<pre><code class="language-sql">SELECT DISTINCT name FROM Table;
</code></pre>
<p>对于流式查询，计算查询结果所需的 State可能会无限增长，用户需要自己控制查询的状态范围，以防止状态过大。</p>
<h2 id="24-group-by">2.4 GROUP BY</h2>
<blockquote>
<p>GROUP BY ：是对数据进行分组操作。例如我们需要计算成绩明细表中，每个学生的总分。</p>
</blockquote>
<p>示例：</p>
<pre><code class="language-java">SELECT name, SUM(score) as TotalScore FROM Table GROUP BY name;
</code></pre>
<h2 id="25-union-和-union-all">2.5 UNION 和 UNION ALL</h2>
<blockquote>
<p>UNION: 用于将两个结果集合并起来，要求两个结果集字段完全一致，包括字段类型、字段顺序。不同于 UNION ALL 的是，UNION 会对结果数据去重。</p>
</blockquote>
<p>示例：</p>
<pre><code class="language-java">SELECT * FROM T1 UNION (ALL) SELECT * FROM T2；
</code></pre>
<h2 id="26-join">2.6 JOIN</h2>
<blockquote>
<p>JOIN ：用于把来自两个表的数据联合起来形成结果表，Flink支持的JOIN 类型包括：</p>
</blockquote>
<ul>
<li>
<p>JOIN - INNER JOIN</p>
</li>
<li>
<p>LEFT JOIN - LEFT OUTER JOIN</p>
</li>
<li>
<p>RIGHT JOIN - RIGHT OUTER JOIN</p>
</li>
<li>
<p>FULL JOIN - FULL OUTER JOIN</p>
</li>
</ul>
<p>这里的 JOIN的语义和我们在关系型数据库中使用的 JOIN 语义一致。</p>
<p>示例：JOIN(将订单表数据和商品表进行关联)</p>
<pre><code class="language-java">SELECT * FROM Orders INNER JOIN Product ON Orders.productId = Product.id
</code></pre>
<p>LEFT JOIN与 JOIN 的区别是当右表没有与左边相 JOIN 的数据时候，右边对应的字段补NULL输出，RIGHT JOIN 相当于LEFT JOIN左右两个表交互一下位置。FULL JOIN相当于RIGHT JOIN 和 LEFT JOIN之后进行UNION ALL 操作，示例：</p>
<pre><code class="language-java">SELECT * FROM Orders LEFT JOIN Product ON Orders.productId = Product.id
SELECT * FROM Orders RIGHT JOIN Product ON Orders.productId = Product.id
SELECT * FROM Orders FULL OUTER JOIN Product ON Orders.productId = Product.id
</code></pre>
<h1 id="3-窗口window">3 窗口(window)</h1>
<h1 id="3-聚合aggregation查询">3 聚合（Aggregation）查询</h1>
<h2 id="31-ttl">3.1 TTL</h2>
<p>在持续查询的过程中，由于用于分组的 key 可能会不断增加，因此计算结果所需要<br>
维护的状态也会持续增长。为了防止状态无限增长耗尽资源</p>
<p><strong>方式1</strong></p>
<pre><code class="language-java">TableEnvironment tableEnv = ...
// 获取表环境的配置
TableConfig tableConfig = tableEnv.getConfig();
// 配置状态保持时间
tableConfig.setIdleStateRetention(Duration.ofMinutes(60));
</code></pre>
<p><strong>方式2</strong></p>
<pre><code class="language-java">TableEnvironment tableEnv = ...
Configuration configuration = tableEnv.getConfig().getConfiguration();
configuration.setString(&quot;table.exec.state.ttl&quot;, &quot;60 min&quot;);
</code></pre>
<h2 id="32-分组聚合">3.2 分组聚合</h2>
<p>运用</p>
<pre><code class="language-java">Table eventCountTable = tableEnv.sqlQuery(&quot;SELECT user, COUNT(url) as cnt FROM EventTable GROUP BY user&quot;);
</code></pre>
<p><strong>csv数据</strong></p>
<pre><code class="language-java">Mary,./home,1000
Alice,./cart,2000
Bob,./prod?id=100,3000
Bob,./cart,4000
Bob,./home,5000
Mary,./home,6000
Bob,./cart,7000
Bob,./home,8000
Bob,./prod?id=10,9000
Bob,./prod?id=10,11000
Bob,./prod?id=10,13000
Bob,./prod?id=10,15000
</code></pre>
<pre><code class="language-java">public class TimeAndWindowTest {
    public static void main(String[] args) throws Exception{
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);

        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);
    
        //1. 在创建表的DDL中直接定义时间属性
        String createDDL = &quot;CREATE TABLE clickTable (&quot; +
                &quot; user_name STRING, &quot; +
                &quot; url STRING, &quot; +
                &quot; ts BIGINT,&quot; +
                &quot; et AS TO_TIMESTAMP(FROM_UNIXTIME(ts/1000)),&quot; +//TO_TIMESTAMP要String,使用FROM_UNIXTIME转成string传入，ts/1000是秒
                &quot; WATERMARK FOR et AS et - INTERVAL '1' SECOND &quot; +//水位线
                &quot; ) WITH (&quot; +
                &quot; 'connector' = 'filesystem',&quot; +
                &quot; 'path' = 'input/clicks.csv',&quot;+
                &quot; 'format' = 'csv'&quot; +
                &quot;) &quot;;
    
        tableEnv.executeSql(createDDL);
    
        //2.在流转换成Table的时候定义时间属性
        SingleOutputStreamOperator&lt;Event&gt; clickStream = env.addSource(new ClickSource())
                .assignTimestampsAndWatermarks(WatermarkStrategy.&lt;Event&gt;forBoundedOutOfOrderness(Duration.ZERO)
                        .withTimestampAssigner(new SerializableTimestampAssigner&lt;Event&gt;() {
                            @Override
                            public long extractTimestamp(Event element, long recordTimestamp) {
                                return element.timestamp;
                            }
                        }));
        Table clickTable = tableEnv.fromDataStream(clickStream, $(&quot;user&quot;), $(&quot;url&quot;), $(&quot;timestamp&quot;).as(&quot;ts&quot;),
                $(&quot;et&quot;).rowtime());
    
        //3.聚合查询转换
        //3.1 分组聚合
        Table aggTable = tableEnv.sqlQuery(&quot;select user_name,count(url) from clickTable group by user_name&quot;);
    
        //3.2 分组窗口聚合
        Table groupWindowResultTable = tableEnv.sqlQuery(&quot;select &quot; +
                &quot; user_name,count(1) as cnt,&quot; +
                &quot; TUMBLE_END(et,INTERVAL '10' SECOND) as entT &quot; +
                &quot; from clickTable group by user_name,&quot; +
                &quot; TUMBLE(et,INTERVAL '10' SECOND)&quot;);


        //clickTable.printSchema();
        tableEnv.toChangelogStream(aggTable).print(&quot;agg&quot;);
        tableEnv.toChangelogStream(groupWindowResultTable).print(&quot;group window&quot;);
        env.execute();

    }
</code></pre>
<p><strong>agg结果</strong></p>
<pre><code class="language-java">agg&gt; +I[Mary, 1]
agg&gt; +I[Alice, 1]
agg&gt; +I[Bob, 1]
agg&gt; -U[Bob, 1]
agg&gt; +U[Bob, 2]
agg&gt; -U[Bob, 2]
agg&gt; +U[Bob, 3]
agg&gt; -U[Mary, 1]
agg&gt; +U[Mary, 2]
agg&gt; -U[Bob, 3]
agg&gt; +U[Bob, 4]
agg&gt; -U[Bob, 4]
agg&gt; +U[Bob, 5]
agg&gt; -U[Bob, 5]
agg&gt; +U[Bob, 6]
agg&gt; -U[Bob, 6]
agg&gt; +U[Bob, 7]
agg&gt; -U[Bob, 7]
agg&gt; +U[Bob, 8]
agg&gt; -U[Bob, 8]
agg&gt; +U[Bob, 9]
</code></pre>
<p><strong>group window结果</strong></p>
<pre><code class="language-java">group window:&gt; +I[Mary, 2, 1970-01-01T08:00:10]
group window:&gt; +I[Alice, 1, 1970-01-01T08:00:10]
group window:&gt; +I[Bob, 6, 1970-01-01T08:00:10]
group window:&gt; +I[Bob, 3, 1970-01-01T08:00:20]
表示Mary在第一个十秒之内有2次点击，Bob6次，Alice1次
在第二个窗口十秒中，Bob有3次
</code></pre>
<h2 id="33-分组窗口">3.3 分组窗口</h2>
<p>在 Flink 1.12 之前的版本中，Table API 和 SQL 提供了一组“分组窗口”（Group Window）函数，常用的时间窗口如滚动窗口、滑动窗口、会话窗口都有对应的实现；具体在 SQL 中就是调用 TUMBLE()、HOP()、SESSION()，传入时间属性字段、窗口大小等参数就可以了。</p>
<h3 id="331-老版本">3.3.1 老版本</h3>
<pre><code class="language-java">Table result = tableEnv.sqlQuery(
 &quot;SELECT &quot; +
 &quot;user, &quot; +
&quot;TUMBLE_END(ts, INTERVAL '1' HOUR) as endT, &quot; +
 &quot;COUNT(url) AS cnt &quot; +
 &quot;FROM EventTable &quot; +
 &quot;GROUP BY &quot; + // 使用窗口和用户名进行分组
 &quot;user, &quot; +
 &quot;TUMBLE(ts, INTERVAL '1' HOUR)&quot; // 定义 1 小时滚动窗口
 );
</code></pre>
<p>这里定义了 1 小时的滚动窗口，将窗口和用户 user 一起作为分组的字段。用聚合函数COUNT()对分组数据的个数进行了聚合统计，并将结果字段重命名为cnt；用TUPMBLE_END()函数获取滚动窗口的结束时间，重命名为 endT 提取出来。</p>
<h3 id="332-新版本窗口表值函数-windowing-tvfs">3.3.2 新版本（窗口表值函数 Windowing TVFs）</h3>
<p>从 1.13 版本开始，Flink 开始使用窗口表值函数（Windowing table-valued functions，Windowing TVFs）来定义窗口。窗口表值函数是 Flink 定义的多态表函数（PTF），可以将表进行扩展后返回。表函数（table function）可以看作是返回一个表的函数</p>
<p><strong>案例</strong></p>
<pre><code class="language-java">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);

        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);
        TableConfig config = tableEnv.getConfig();
        config.setIdleStateRetention(Duration.ofMillis(60));
    
        SingleOutputStreamOperator&lt;Event&gt; dataStream = env.addSource(new ClickSource()).assignTimestampsAndWatermarks(WatermarkStrategy.&lt;Event&gt;forBoundedOutOfOrderness(Duration.ZERO)
                .withTimestampAssigner(new SerializableTimestampAssigner&lt;Event&gt;() {
                    @Override
                    public long extractTimestamp(Event element, long recordTimestamp) {
                        return element.getTimestamp();
                    }
                }));
    
        // 1. 注册虚拟表
        tableEnv.createTemporaryView(&quot;table_click&quot;, dataStream, $(&quot;user&quot;), $(&quot;ts&quot;).rowtime());
    
        // 2. 窗口聚合查询 老版本-滚动窗口
        Table agg = tableEnv.sqlQuery(&quot;select &quot; +
                &quot; user,&quot; +
                &quot; count(1) AS ct,&quot; +
                &quot; TUMBLE_END(ts,INTERVAL '10' SECOND) AS endTime&quot; +
                &quot; from table_click &quot; +
                &quot; group by user, TUMBLE(ts, INTERVAL '10' SECOND)&quot;); // 滚动窗口 布长10
    
        // 3. 窗口聚合查询 TVF-滚动窗口
        Table tvfTumbleAgg = tableEnv.sqlQuery(&quot;select &quot; +
                &quot; user,&quot; +
                &quot; count(1) AS ct,&quot; +
                &quot; window_start,&quot; +
                &quot; window_end&quot; +
                &quot; from TABLE(&quot; + // 创建一个滚动窗口,参数1:数据来源的虚拟表,参数2:滚动日期参数，参数3：窗口布长
                &quot; TUMBLE(table table_click, DESCRIPTOR(ts), INTERVAL '10' SECOND))&quot; +
                &quot; GROUP BY user, window_start, window_end&quot;); // group by window_start, window_end 固定写法
    
        // 4. 窗口聚合查询 TVF-滑动窗口
        Table tvfHopAgg = tableEnv.sqlQuery(&quot;select &quot; +
                &quot; user,&quot; +
                &quot; count(1) AS ct,&quot; +
                &quot; window_start,&quot; +
                &quot; window_end&quot; +
                &quot; from TABLE(&quot; + // 创建一个滚动窗口,参数1:数据来源的虚拟表,参数2:滚动日期参数，参数3：滑动补布长 参数4：窗口布长
                &quot; HOP(table table_click, DESCRIPTOR(ts), INTERVAL '5' SECOND,INTERVAL '10' SECOND))&quot; +
                &quot; GROUP BY user, window_start, window_end&quot;); // group by window_start, window_end 固定写法
    
        // 5. 累计窗口
        Table tvfCumulateAgg = tableEnv.sqlQuery(&quot;select &quot; +
                &quot; CURRENT_TIME as cutTime,&quot; +
                &quot; user,&quot; +
                &quot; count(1) AS ct,&quot; +
                &quot; window_start,&quot; +
                &quot; window_end&quot; +
                &quot; from TABLE(&quot; + // 创建一个滚动窗口,参数1:数据来源的虚拟表,参数2:滚动日期参数，参数3：每隔多久计算输出一次 参数4：全窗口布长
                &quot; CUMULATE(table table_click, DESCRIPTOR(ts), INTERVAL '5' SECOND,INTERVAL '10' SECOND))&quot; +
                &quot; GROUP BY user, window_start, window_end&quot;); // group by window_start, window_end 固定写法
    
        dataStream.print(&quot;source:&quot;);
        //tableEnv.toChangelogStream(agg).print(&quot;agg:&quot;);
        //tableEnv.toChangelogStream(tvfTumbleAgg).print(&quot;tvfTumbleAgg:&quot;);
        //tableEnv.toChangelogStream(tvfHopAgg).print(&quot;tvfHotAgg:&quot;);
        tableEnv.toChangelogStream(tvfCumulateAgg).print(&quot;tvfCumulateAgg:&quot;);

</code></pre>
<blockquote>
<p>注意：GROUP BY window_start, window_end 是固定写法</p>
</blockquote>
<h2 id="34-开窗over聚合">3.4 开窗（Over）聚合</h2>
<p>Flink SQL 中的开窗函数也是通过 OVER 子句来实现的</p>
<h3 id="341-语法">3.4.1 语法</h3>
<pre><code class="language-java"> &lt;聚合函数&gt; OVER (
 [PARTITION BY &lt;字段 1&gt;[, &lt;字段 2&gt;, ...]]
 ORDER BY &lt;时间属性字段&gt;
 &lt;开窗范围&gt;),
 ...
FROM ...
</code></pre>
<ul>
<li>
<p>PARTITION BY（可选）<br>
用来指定分区的键（key），类似于 GROUP BY 的分组，这部分是可选的</p>
</li>
<li>
<p>ORDER BY<br>
OVER 窗口是基于当前行扩展出的一段数据范围，选择的标准可以基于时间也可以基于数量。不论那种定义，数据都应该是以某种顺序排列好的；而表中的数据本身是无序的。所以在OVER 子句中必须用 ORDER BY 明确地指出数据基于那个字段排序。在 Flink 的流处理中，目前只支持按照时间属性的升序排列，所以这里 ORDER BY 后面的字段必须是定义好的时间属性。</p>
</li>
<li>
<p>开窗范围<br>
对于开窗函数而言，还有一个必须要指定的就是开窗的范围，也就是到底要扩展多少行来做聚合。这个范围是由 BETWEEN &lt;下界&gt; AND &lt;上界&gt; 来定义的，也就是“从下界到上界”的范围。目前支持的上界只能是 CURRENT ROW，也就是定义一个“从之前某一行到当前行”的范围，所以一般的形式为：</p>
</li>
</ul>
<pre><code class="language-java">PRECEDING 指前面几个/前一段时间；CURRENT ROW：指到当前最新得行数

BETWEEN ... PRECEDING AND CURRENT ROW
</code></pre>
<ul>
<li>范围间隔<br>
范围间隔以 RANGE 为前缀，就是基于 ORDER BY 指定的时间字段去选取一个范围，一般就是当前行时间戳之前的一段时间。例如开窗范围选择当前行之前 1 小时的数据：</li>
</ul>
<pre><code class="language-java">RANGE BETWEEN INTERVAL '1' HOUR PRECEDING AND CURRENT ROW
</code></pre>
<ul>
<li>行间隔<br>
行间隔以 ROWS 为前缀，就是直接确定要选多少行，由当前行出发向前选取就可以了。<br>
例如开窗范围选择当前行之前的 5 行数据（最终聚合会包括当前行，所以一共 6 条数据）</li>
</ul>
<pre><code class="language-java">ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
</code></pre>
<pre><code class="language-java">SELECT user,
 COUNT(url) OVER (
 PARTITION BY user
 ORDER BY ts
 RANGE BETWEEN INTERVAL '1' HOUR PRECEDING AND CURRENT ROW
 ) AS cnt
FROM EventTable
</code></pre>
<h1 id="4-topn-example">4 topN example</h1>
<pre><code class="language-java">import com.flink.dto.Event;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.Table;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

import static org.apache.flink.table.api.Expressions.$;

public class WindowTopNExample {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env =
                StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        // 读取数据源，并分配时间戳、生成水位线
        SingleOutputStreamOperator&lt;Event&gt; eventStream = env
                .fromElements(
                        new Event(&quot;Alice&quot;, &quot;./home&quot;, 1000L),
                        new Event(&quot;Bob&quot;, &quot;./cart&quot;, 1000L),
                        new Event(&quot;Alice&quot;, &quot;./prod?id=1&quot;, 25 * 60 * 1000L),
                        new Event(&quot;Alice&quot;, &quot;./prod?id=4&quot;, 55 * 60 * 1000L),
                        new Event(&quot;Bob&quot;, &quot;./prod?id=5&quot;, 3600 * 1000L + 60 * 1000L),
                        new Event(&quot;Cary&quot;, &quot;./home&quot;, 3600 * 1000L + 30 * 60 * 1000L),
                        new Event(&quot;Cary&quot;, &quot;./prod?id=7&quot;, 3600 * 1000L + 59 * 60 * 1000L)
                ).assignTimestampsAndWatermarks(WatermarkStrategy.&lt;Event&gt;forMonotonousTimestamps()
                        .withTimestampAssigner(new SerializableTimestampAssigner&lt;Event&gt;() {
                            @Override
                            public long extractTimestamp(Event element, long
                                    recordTimestamp) {
                                return element.getTimestamp();
                            }
                        }));
        // 创建表环境
        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);
        // 将数据流转换成表，并指定时间属性
        Table eventTable = tableEnv.fromDataStream(
                eventStream,
                $(&quot;user&quot;),
                $(&quot;url&quot;),
                $(&quot;timestamp&quot;).rowtime().as(&quot;ts&quot;)  // 将 timestamp 指定为事件时间，并命名为 ts
        );
        // 为方便在 SQL 中引用，在环境中注册表 EventTable
        tableEnv.createTemporaryView(&quot;EventTable&quot;, eventTable);
        // 定义子查询，进行窗口聚合，得到包含窗口信息、用户以及访问次数的结果表
        String subQuery =
                &quot;SELECT window_start, window_end, user, COUNT(url) as cnt &quot; +
                        &quot;FROM TABLE ( &quot; +
                        &quot;TUMBLE( TABLE EventTable, DESCRIPTOR(ts), INTERVAL '1' HOUR )) &quot; + // 滚动窗口 布长1小时
                        &quot;GROUP BY window_start, window_end, user &quot;;
        // 定义 Top N 的外层查询
        String topNQuery =
                &quot;SELECT * &quot; +
                        &quot;FROM (&quot; +
                        &quot;SELECT *, &quot; +
                        &quot;ROW_NUMBER() OVER ( &quot; +
                        &quot;PARTITION BY window_start, window_end &quot; +
                        &quot;ORDER BY cnt desc &quot; +
                        &quot;) AS row_num &quot; +
                        &quot;FROM (&quot; + subQuery + &quot;)) &quot; +
                        &quot;WHERE row_num &lt;= 2&quot;;
        // 执行 SQL 得到结果表
        Table result = tableEnv.sqlQuery(topNQuery);
        tableEnv.toDataStream(result).print();
        env.execute();
    }
}
</code></pre>
<h1 id="5-联结查询">5 联结查询</h1>
<h2 id="51-常规联结查询">5.1 常规联结查询</h2>
<p>等值内连接<br>
等值外连接<br>
这部分跟标准SQL一样呢，就不赘述啦</p>
<h2 id="52-间隔联结查询">5.2  间隔联结查询</h2>
<p><strong>1.时间间隔限制</strong></p>
<pre><code class="language-java">ltime BETWEEN rtime - INTERVAL '10' SECOND AND rtime + INTERVAL '5' SECOND
</code></pre>
<pre><code class="language-java">SELECT *
FROM Order o, Shipment s
WHERE o.id = s.order_id
AND o.order_time BETWEEN s.ship_time - INTERVAL '4' HOUR AND s.ship_time
</code></pre>
<p>在流处理中，间隔联结查询只支持具有时间属性的“仅追加”（Append-only）表。</p>

          <div class="toc-container"><ul class="markdownIt-TOC">
<li><a href="#flink-tablesql">Flink Table&amp;SQL</a>
<ul>
<li><a href="#maven-%E4%BE%9D%E8%B5%96%E5%BC%95%E7%94%A8">maven 依赖引用</a></li>
</ul>
</li>
<li><a href="#%E6%97%B6%E9%97%B4%E5%B1%9E%E6%80%A7">时间属性</a>
<ul>
<li><a href="#1-%E4%BA%8B%E4%BB%B6%E6%97%B6%E9%97%B4">1 事件时间</a></li>
<li><a href="#2-%E5%A4%84%E7%90%86%E6%97%B6%E9%97%B4">2 处理时间</a></li>
<li><a href="#11-%E6%A1%88%E4%BE%8B1datastream-sql%E7%BB%9F%E8%AE%A1">1.1 案例1（DataStream SQL统计）</a></li>
<li><a href="#12-%E6%A1%88%E4%BE%8B2datastream-tablesql%E7%BB%9F%E8%AE%A1">1.2 案例2（DataStream Table&amp;SQL统计）</a></li>
<li><a href="#14-%E6%A1%88%E4%BE%8B4sql%E6%B6%88%E8%B4%B9kafka">1.4 案例4（SQL消费Kafka）</a></li>
</ul>
</li>
<li><a href="#2-flink-sql%E5%B8%B8%E7%94%A8%E7%AE%97%E5%AD%90">2 Flink SQL常用算子</a>
<ul>
<li><a href="#21-select">2.1 SELECT</a></li>
<li><a href="#22-where">2.2 WHERE</a></li>
<li><a href="#23-distinct">2.3 DISTINCT</a></li>
<li><a href="#24-group-by">2.4 GROUP BY</a></li>
<li><a href="#25-union-%E5%92%8C-union-all">2.5 UNION 和 UNION ALL</a></li>
<li><a href="#26-join">2.6 JOIN</a></li>
</ul>
</li>
<li><a href="#3-%E7%AA%97%E5%8F%A3window">3 窗口(window)</a></li>
<li><a href="#3-%E8%81%9A%E5%90%88aggregation%E6%9F%A5%E8%AF%A2">3 聚合（Aggregation）查询</a>
<ul>
<li><a href="#31-ttl">3.1 TTL</a></li>
<li><a href="#32-%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88">3.2 分组聚合</a></li>
<li><a href="#33-%E5%88%86%E7%BB%84%E7%AA%97%E5%8F%A3">3.3 分组窗口</a>
<ul>
<li><a href="#331-%E8%80%81%E7%89%88%E6%9C%AC">3.3.1 老版本</a></li>
<li><a href="#332-%E6%96%B0%E7%89%88%E6%9C%AC%E7%AA%97%E5%8F%A3%E8%A1%A8%E5%80%BC%E5%87%BD%E6%95%B0-windowing-tvfs">3.3.2 新版本（窗口表值函数 Windowing TVFs）</a></li>
</ul>
</li>
<li><a href="#34-%E5%BC%80%E7%AA%97over%E8%81%9A%E5%90%88">3.4 开窗（Over）聚合</a>
<ul>
<li><a href="#341-%E8%AF%AD%E6%B3%95">3.4.1 语法</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#4-topn-example">4 topN example</a></li>
<li><a href="#5-%E8%81%94%E7%BB%93%E6%9F%A5%E8%AF%A2">5 联结查询</a>
<ul>
<li><a href="#51-%E5%B8%B8%E8%A7%84%E8%81%94%E7%BB%93%E6%9F%A5%E8%AF%A2">5.1 常规联结查询</a></li>
<li><a href="#52-%E9%97%B4%E9%9A%94%E8%81%94%E7%BB%93%E6%9F%A5%E8%AF%A2">5.2  间隔联结查询</a></li>
</ul>
</li>
</ul>
</div>
          <hr />
          
            <p class="prev-post">上一篇：
              <a href="https://tianxiawuhao.github.io/EEiV7EREL/">
                <span class="post-title">
                  附录 Flink常见面试问题汇总&rarr;
                </span>
              </a>
            </p>
          
          
          <p class="next-post">下一篇：
            <a href="https://tianxiawuhao.github.io/tloS_nSAM/">
              <span class="post-title">
                第十章 Table API 与 SQL&rarr;
              </span>
            </a>
          </p>
          
          <div class="comment" style="text-align: center;">
            

            
            
          </div>
        </div>
      </div>
    </div>
  </article>
  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <ul class="list-inline text-center">
            
            
              
            
              
            
              
            
              
            
              
            
              
            
              
              <!-- <li class="list-inline-item">
              <a href="https://tianxiawuhao.github.io/atom.xml" target="_blank">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
                </span>
              </a>
              </li> -->
          </ul>
          <p class="copyright text-muted">Copyright &copy;<span>tianxia</span><br><a href="https://github.com/getgridea/gridea" class="Themeinfo">Powered by Gridea</a></p>
        </div>
      </div>
    </div>
   </footer>
  <!-- Bootstrap core JavaScript -->
  <script src="https://cdn.bootcss.com/twitter-bootstrap/4.3.1/js/bootstrap.bundle.min.js"></script>
  <!-- <script src="https://tianxiawuhao.github.io/media/scripts/bootstrap.bundle.min.js"></script> -->
  <!-- Bootstrap core JavaScript -->
  <script src="https://cdn.jsdelivr.net/gh/Alanrk/clean-cdn@1.0/scripts/clean-blog.min.js"></script>
  <!-- <script src="https://tianxiawuhao.github.io/media/scripts/clean-blog.min.js"></script> -->
  <script src="//instant.page/3.0.0" type="module" defer integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1"></script>
  <style type="text/css">a.back_to_top{text-decoration:none;position:fixed;bottom:40px;right:30px;background:#f0f0f0;height:40px;width:40px;border-radius:50%;line-height:36px;font-size:18px;text-align:center;transition-duration:.5s;transition-propety:background-color;display:none}a.back_to_top span{color:#888}a.back_to_top:hover{cursor:pointer;background:#dfdfdf}a.back_to_top:hover span{color:#555}@media print,screen and(max-width:580px){.back_to_top{display:none!important}}</style>
<a id="back_to_top" href="#" class="back_to_top">
  <span>▲</span></a>
<script>$(document).ready((function(_this) {
    return function() {
      var bt;
      bt = $('#back_to_top');
      if ($(document).width() > 480) {
        $(window).scroll(function() {
          var st;
          st = $(window).scrollTop();
          if (st > 30) {
            return bt.css('display', 'block')
          } else {
            return bt.css('display', 'none')
          }
        });
        return bt.click(function() {
          $('body,html').animate({
            scrollTop: 0
          },
          800);
          return false
        })
      }
    }
  })(this));</script>
  
  <script src="https://tianxiawuhao.github.io/media/scripts/tocScript.js"></script>
</body>

</html>